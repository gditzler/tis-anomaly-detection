{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# About \r\n",
                "\r\n",
                "This notebook summarizes the detection results for the TIS anomaly detector that uses an autoencoder to learn the normal behavior of a user on a Windows computer. The neural network is trained on six hours of data and the result files, located in `results/` have the pickle files for training on one hour increments. We only consider the neural network trained on six hours in this notebook. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import numpy as np \r\n",
                "import matplotlib.pylab as plt\r\n",
                "from utils import read_result_file, get_rates, label_window\r\n",
                "from sklearn.metrics import roc_curve\r\n",
                "from sklearn.metrics import roc_auc_score\r\n",
                "\r\n",
                "plt.style.use('ggplot')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Standard Results \r\n",
                "\r\n",
                "In this section, we load the data from the result file. We are only loading the data that were procuced by the autoencoder that was trained on six hours of data, which is the longest training duration that we have collected.  The reconstruction errors for the attacks are saved in a list that we concatenate together. The detection peformance is measure for by determining the detections for each sample then finding the statistics of interest for classification. These results are the same as the onces that were prepared for the duration of thr TIS project. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# load the result files\r\n",
                "file_path_results = 'results/results_round_6_max_training_hrs8.pkl' \r\n",
                "threshold, errs_attack, errs_normal, errs_train = read_result_file(file_path_results)\r\n",
                "# threshold = 0.4\r\n",
                "\r\n",
                "# get the lengths of the normal and attack datasets. note these are going to be different if we use a window \r\n",
                "n_normal = len(errs_normal)\r\n",
                "n_attack = np.array([len(errs_attack[i]) for i in range(len(errs_attack))]).sum()\r\n",
                "\r\n",
                "# classify the data with the pre-determined threshold the create the ground truth label vector \r\n",
                "scores_attack = np.concatenate(tuple(errs_attack))\r\n",
                "yhat = np.concatenate((1*(errs_normal > threshold), 1*(scores_attack > threshold)))\r\n",
                "y = np.concatenate((np.zeros(n_normal), np.ones(n_attack)))\r\n",
                "scores = np.concatenate((errs_normal, scores_attack))\r\n",
                "\r\n",
                "# get the detection results and print them out \r\n",
                "_ = get_rates(y, yhat, verbose=True)\r\n",
                "\r\n",
                "print(''.join(['The threshold is ', str(threshold)]))\r\n",
                "\r\n",
                "# plot the ROC\r\n",
                "fpr_orig, tpr_orig, thresholds_orig = roc_curve(y, scores)\r\n",
                "auc_orig = roc_auc_score(y, scores, average='micro')\r\n",
                "\r\n",
                "plt.figure()\r\n",
                "plt.plot(fpr_orig, tpr_orig, c='b', label=''.join(['AUC=', str(round(auc_orig, 3))]))\r\n",
                "plt.xlabel('False Positive Rate')\r\n",
                "plt.ylabel('True Positive Rate')\r\n",
                "plt.legend()\r\n",
                "plt.savefig('outputs/roc_original.pdf')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Window Results \r\n",
                "\r\n",
                "\r\n",
                "In this section, we implement a sliding window to form the final classification decision. We consider a sequence of predictions $\\hat{y}_1, \\hat{y}_2, \\ldots, \\hat{y}_t$. There is a window size $K$, which is an odd number, and we perform a majority vote over the window to make the final detection decision. Note this method has the potential to cause a lag time in the detection; however, the new feature collector is fast enough that the system will still be faster than the Python data collection tool. "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "window_size = 3\r\n",
                "y_hat_attack_window, scores_hat_attack_window = [], []\r\n",
                "y_hat_normal_window, scores_hat_normal_window = label_window(1*(errs_normal > threshold), window_size=window_size)\r\n",
                "for i in range(len(errs_attack)): \r\n",
                "    pred, score = label_window(1*(errs_attack[i] > threshold), window_size=window_size)\r\n",
                "    y_hat_attack_window.append(pred)\r\n",
                "    scores_hat_attack_window.append(score) \r\n",
                "\r\n",
                "# get the lengths of the normal and attack datasets.  \r\n",
                "n_normal = len(y_hat_normal_window)\r\n",
                "n_attack = np.array([len(y_hat_attack_window[i]) for i in range(len(y_hat_attack_window))]).sum()\r\n",
                "\r\n",
                "# generate the ground truth and detection vectors \r\n",
                "y = np.concatenate((np.zeros(n_normal), np.ones(n_attack)))\r\n",
                "yhat = np.concatenate((y_hat_normal_window, np.concatenate(tuple(y_hat_attack_window))))\r\n",
                "scores = np.concatenate((scores_hat_normal_window, np.concatenate(tuple(scores_hat_attack_window))))\r\n",
                "\r\n",
                "# get detection results and print them out  \r\n",
                "_ = get_rates(y, yhat, verbose=True)\r\n",
                "\r\n",
                "# plot the ROC\r\n",
                "fpr_win, tpr_win, thresholds_win = roc_curve(y, scores)\r\n",
                "auc_win = roc_auc_score(y, scores, average='micro')\r\n",
                "\r\n",
                "plt.figure()\r\n",
                "plt.plot(fpr_win, tpr_win, c='b', label=''.join(['AUC=', str(round(auc_win, 3))]))\r\n",
                "plt.xlabel('False Positive Rate')\r\n",
                "plt.ylabel('True Positive Rate')\r\n",
                "plt.legend()\r\n",
                "plt.savefig('outputs/roc_window.pdf')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Plots "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "plt.figure()\r\n",
                "\r\n",
                "for i in range(len(errs_attack)): \r\n",
                "    plt.hist(errs_attack[i], label=''.join(['Attack ', str(i)]), stacked=True)\r\n",
                "plt.hist(errs_normal, label='Normal', stacked=True)\r\n",
                "plt.xlabel('Reconstruction Error')\r\n",
                "plt.ylabel('Density')\r\n",
                "plt.legend()\r\n",
                "plt.savefig('outputs/density_attack.pdf')\r\n",
                "\r\n",
                "\r\n",
                "plt.figure()\r\n",
                "plt.hist(errs_normal, label='Normal', density=True)\r\n",
                "plt.legend()\r\n",
                "plt.xlabel('Reconstruction Error')\r\n",
                "plt.ylabel('Density')\r\n",
                "plt.savefig('outputs/density_normal.pdf')\r\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# generate plots of the sorted reconstruction errors \r\n",
                "plt.figure()\r\n",
                "for i in range(len(errs_attack)): \r\n",
                "    plt.plot(np.sort(errs_attack[i]))\r\n",
                "plt.xlabel('Sample Number')\r\n",
                "plt.ylabel('Reconstruction Error')\r\n",
                "plt.savefig('outputs/reconerr_attacks.pdf')\r\n",
                "\r\n",
                "plt.figure()\r\n",
                "plt.plot(np.sort(errs_normal), c='b')\r\n",
                "plt.xlabel('Sample Number')\r\n",
                "plt.ylabel('Reconstruction Error')\r\n",
                "plt.savefig('outputs/reconerr_normal.pdf')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "print(''.join(['Normal: ', str(np.mean(errs_normal))]))\r\n",
                "for i in range(len(errs_attack)): \r\n",
                "    print(''.join(['Attack ', str(i+1), ': ', str(np.mean(errs_attack[i]))]))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "plt.figure()\r\n",
                "plt.plot(fpr_orig, tpr_orig, c='r', label=''.join(['Original AUC=', str(round(auc_orig, 3))]))\r\n",
                "plt.plot(fpr_win, tpr_win, c='b', label=''.join(['Window AUC=', str(round(auc_win, 3))]))\r\n",
                "plt.xlabel('False Positive Rate')\r\n",
                "plt.ylabel('True Positive Rate')\r\n",
                "plt.legend()\r\n",
                "plt.savefig('outputs/roc_original_window.pdf')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.11",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.11 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "0fd9392274fc82a63c2a75f43f796d95e051853c3a46ffe4696bb4291dc65e3b"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}